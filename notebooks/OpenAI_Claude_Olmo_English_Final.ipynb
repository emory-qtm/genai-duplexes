{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDEOFgoGsQww"
      },
      "source": [
        "OpenAI Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4276a9d4",
        "outputId": "0b7a36d1-2659-4051-9ee6-f907ab66558f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.9.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Downloading openai-2.9.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.8.1\n",
            "    Uninstalling openai-2.8.1:\n",
            "      Successfully uninstalled openai-2.8.1\n",
            "Successfully installed openai-2.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install the newer OpenAI SDK\n",
        "!pip install --upgrade openai\n",
        "\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import random\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4_zh0XgDuvk"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=\"KEY_GOES_HERE\")\n",
        "\n",
        "def query_chatGPT(prompt):\n",
        "    \"\"\"Send a prompt to OpenAI GPT-4o.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",       # you can change to gpt-4o if you want\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=400,\n",
        "        temperature=1\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF5AHGO6_Ef-",
        "outputId": "22fcad2d-301d-44a4-e4f5-1373f1a9f947"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SqTw3A99hPDbTUxZ-OoJD4wGdl0ZF3Oz\n",
            "To: /content/brown_poems.csv\n",
            "100%|██████████| 3.18k/3.18k [00:00<00:00, 7.24MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download public domain poems\n",
        "poems_df = pd.read_csv(\n",
        "    'https://github.com/maria-antoniak/poetry-eval/'\n",
        "    'raw/refs/heads/main/data/poetry-evaluation_public-domain-poems.csv'\n",
        ")\n",
        "\n",
        "# keep sonnets & ghazals\n",
        "poems_df = poems_df[poems_df['form'].isin(['sonnet', 'ghazal'])]\n",
        "\n",
        "# random 25 sonnets + 2 ghazals\n",
        "sample_df = poems_df[poems_df['form'] == 'sonnet'].sample(25)\n",
        "sample_df = pd.concat([sample_df, poems_df[poems_df['form'] == 'ghazal']])\n",
        "\n",
        "# load brown poems\n",
        "import gdown\n",
        "url = \"https://drive.google.com/file/d/1SqTw3A99hPDbTUxZ-OoJD4wGdl0ZF3Oz/view?usp=sharing\"\n",
        "output = \"brown_poems.csv\"\n",
        "gdown.download(url=url, output=output, fuzzy=True)\n",
        "\n",
        "brown_df = pd.read_csv(\"brown_poems.csv\")\n",
        "\n",
        "# reduce sample_df columns\n",
        "sample_df = sample_df[['author', 'poem_title', 'poem_text', 'form']]\n",
        "\n",
        "# combine datasets\n",
        "combined_df = pd.concat([sample_df, brown_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3oAhmdU_Ei0"
      },
      "outputs": [],
      "source": [
        "prompt_template_start = '''\n",
        "Read the following poem and classify its form as: [sonnet, ghazal, duplex].\n",
        "You must choose exactly ONE.\n",
        "\n",
        "Return the answer in this format:\n",
        "\n",
        "1. Poetic Form: ...\n",
        "2. Elaborated Rationale: ...\n",
        "3. One-Word Summary: ...\n",
        "4. Confidence Score: ...\n",
        "\n",
        "Poem Text:\n",
        "'''\n",
        "\n",
        "prompt_template_end = '''\n",
        "\n",
        "Pick ONE of these forms: [sonnet, ghazal, duplex].\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsAUqUUsEBGu"
      },
      "outputs": [],
      "source": [
        "def extract_response_fields(response):\n",
        "    \"\"\"Parse the classification output.\"\"\"\n",
        "    lines = response.strip().split('\\n')\n",
        "\n",
        "    result = {\n",
        "        'poetic_form': None,\n",
        "        'rationale': None,\n",
        "        'summary': None,\n",
        "        'confidence': None\n",
        "    }\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('1. Poetic Form:'):\n",
        "            result['poetic_form'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('2. Elaborated Rationale:'):\n",
        "            result['rationale'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('3. One-Word Summary:'):\n",
        "            result['summary'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('4. Confidence Score:'):\n",
        "            result['confidence'] = line.split(':', 1)[1].strip()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7IwJ24sEBJn"
      },
      "outputs": [],
      "source": [
        "for index, row in combined_df.iterrows():\n",
        "    prompt = prompt_template_start + row['poem_text'] + prompt_template_end\n",
        "    response = query_chatGPT(prompt)\n",
        "    fields = extract_response_fields(response)\n",
        "\n",
        "    combined_df.at[index, 'poetic_form'] = fields['poetic_form']\n",
        "    combined_df.at[index, 'rationale'] = fields['rationale']\n",
        "    combined_df.at[index, 'summary'] = fields['summary']\n",
        "    combined_df.at[index, 'confidence'] = fields['confidence']\n",
        "\n",
        "combined_df.to_csv(\"combined_df.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOdv5ZjCEBMF",
        "outputId": "3f7bd98c-7021-4718-ef2d-f642e4130e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tasks complete.\n"
          ]
        }
      ],
      "source": [
        "subjects = [\n",
        "    \"abuse\",\n",
        "    \"activities\",\n",
        "    \"arts & sciences\",\n",
        "    \"christianity\",\n",
        "    \"chronic illness\",\n",
        "    \"crime & punishment\",\n",
        "    \"cycles\",\n",
        "    \"desire & passion\",\n",
        "    \"doubt & contemplation\",\n",
        "    \"family & ancestors\",\n",
        "    \"gender & sexuality\",\n",
        "    \"greek & roman mythology\",\n",
        "    \"history & politics\",\n",
        "    \"home life\",\n",
        "    \"hope\",\n",
        "    \"humor & satire\",\n",
        "    \"indoor activities\",\n",
        "    \"life choices\",\n",
        "    \"lgbtq+\",\n",
        "    \"living\",\n",
        "    \"love\",\n",
        "    \"love death avoidance\",\n",
        "    \"memory & nostalgia\",\n",
        "    \"men & women\",\n",
        "    \"mythology & folklore\",\n",
        "    \"nature\",\n",
        "    \"power\",\n",
        "    \"poetry & poets\",\n",
        "    \"race & ethnicity\",\n",
        "    \"relationships\",\n",
        "    \"romantic love\",\n",
        "    \"sexual violence\",\n",
        "    \"sorrow & grieving\",\n",
        "    \"social commentaries\",\n",
        "    \"subjugation\",\n",
        "    \"the mind\",\n",
        "    \"trees and flowers\",\n",
        "    \"truth\",\n",
        "    \"twilight\",\n",
        "    \"urban environment\",\n",
        "    \"war & conflict\",\n",
        "    \"weather\",\n",
        "    \"youth\"\n",
        "]\n",
        "\n",
        "\n",
        "def generate_general_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}.\"\n",
        "\n",
        "\n",
        "def generate_figurative_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}. Do not use the words {subject} or {form}.\"\n",
        "\n",
        "\n",
        "def generate_specific_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}. Make it about something specific.\"\n",
        "\n",
        "\n",
        "new_poems_df = pd.DataFrame(columns=['subject', 'form', 'prompt_type', 'poem_text'])\n",
        "\n",
        "for subject in subjects:\n",
        "    genPrompt = generate_general_prompt(subject)\n",
        "    figPrompt = generate_figurative_prompt(subject)\n",
        "    specPrompt = generate_specific_prompt(subject)\n",
        "\n",
        "    genResponse = query_chatGPT(genPrompt)\n",
        "    figResponse = query_chatGPT(figPrompt)\n",
        "    specResponse = query_chatGPT(specPrompt)\n",
        "\n",
        "    new_poems_df.loc[len(new_poems_df)] = [subject, \"Duplex\", \"general\", genResponse]\n",
        "    new_poems_df.loc[len(new_poems_df)] = [subject, \"Duplex\", \"figurative\", figResponse]\n",
        "    new_poems_df.loc[len(new_poems_df)] = [subject, \"Duplex\", \"specific\", specResponse]\n",
        "\n",
        "new_poems_df.to_csv(\"new_poems_df.csv\", index=False)\n",
        "\n",
        "print(\"All tasks complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUsmYuYwJKTL"
      },
      "outputs": [],
      "source": [
        "BROWN_RULES = \"\"\"\n",
        "Write a poem in the Duplex form as defined by Jericho Brown.\n",
        "You MUST follow ALL of these rules:\n",
        "\n",
        "1. The poem has exactly 14 lines.\n",
        "2. Each line must contain between 9 and 11 syllables.\n",
        "3. The poem should blend qualities of ghazal, sonnet, and blues traditions.\n",
        "4. Line 1 is repeated as Line 14.\n",
        "5. Line 2 must reinterpret Line 1 in an unexpected way.\n",
        "6. Line 2 is repeated as Line 3.\n",
        "7. Line 4 must reinterpret Line 3 in an unexpected way.\n",
        "8. This pattern of echo / reinterpretation continues until Line 13.\n",
        "9. Line 13 becomes the first line of the couplet that leads to the final line (Line 14).\n",
        "10. The poem’s theme should be rooted in emotional tension, reflection, or personal revelation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgjJX5KfEBOI"
      },
      "outputs": [],
      "source": [
        "def generate_general_prompt(subject, form=\"Duplex\"):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a poem about the subject of {subject} in the form: {form}.\\n\"\n",
        "        f\"The poem MUST follow all Duplex rules above.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_figurative_prompt(subject, form=\"Duplex\"):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a poem about the subject of {subject} in the form: {form}.\\n\"\n",
        "        f\"Do NOT use the words '{subject}' or '{form}' anywhere in the poem.\\n\"\n",
        "        f\"The poem MUST follow all Duplex rules above.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_specific_prompt(subject, form=\"Duplex\"):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a poem about the subject of {subject} in the form: {form}.\\n\"\n",
        "        f\"Make the poem about a very specific moment, object, place, or memory.\\n\"\n",
        "        f\"The poem MUST follow all Duplex rules above.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeQBCrYAEBQL"
      },
      "outputs": [],
      "source": [
        "new_brown_poems_df = pd.DataFrame(\n",
        "    columns=['subject', 'form', 'prompt_type', 'poem_text']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXQcCh7pKHwc"
      },
      "outputs": [],
      "source": [
        "for subject in subjects:\n",
        "\n",
        "    # build 3 prompt types\n",
        "    genPrompt = generate_general_prompt(subject)\n",
        "    figPrompt = generate_figurative_prompt(subject)\n",
        "    specPrompt = generate_specific_prompt(subject)\n",
        "\n",
        "    # call your model function (this is unchanged)\n",
        "    genResponse = query_chatGPT(genPrompt)\n",
        "    figResponse = query_chatGPT(figPrompt)\n",
        "    specResponse = query_chatGPT(specPrompt)\n",
        "\n",
        "    # store in your preferred format\n",
        "    new_brown_poems_df.loc[len(new_brown_poems_df)] = [\n",
        "        subject, \"Duplex\", \"general\", genResponse\n",
        "    ]\n",
        "    new_brown_poems_df.loc[len(new_brown_poems_df)] = [\n",
        "        subject, \"Duplex\", \"figurative\", figResponse\n",
        "    ]\n",
        "    new_brown_poems_df.loc[len(new_brown_poems_df)] = [\n",
        "        subject, \"Duplex\", \"specific\", specResponse\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi7RxzWxKH3p",
        "outputId": "fc3c59b6-d4ca-48f9-8cb3-87bddaf32d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Duplex poems generated and saved.\n"
          ]
        }
      ],
      "source": [
        "new_brown_poems_df.to_csv(\"new_brown_poems_df.csv\", index=False)\n",
        "\n",
        "print(\"All Duplex poems generated and saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwx71AuksL8U"
      },
      "source": [
        "Claude Generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Iy1gPirrQRp",
        "outputId": "28a5451d-ee98-417d-df7c-a368fca1ea96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.75.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
            "Downloading anthropic-0.75.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.75.0\n"
          ]
        }
      ],
      "source": [
        "# Install the Anthropic SDK\n",
        "!pip install anthropic\n",
        "\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import random\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SziTuM39rQUq"
      },
      "outputs": [],
      "source": [
        "# Initialize the Anthropic client\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=\"KEY_GOES_HERE\"\n",
        ")\n",
        "\n",
        "def query_claude(prompt):\n",
        "    \"\"\"Send a prompt to Claude.\"\"\"\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-sonnet-4-20250514\",\n",
        "        max_tokens=1024,\n",
        "        temperature=1,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YEprnyWrQZn"
      },
      "outputs": [],
      "source": [
        "poems_df = pd.read_csv(\n",
        "    'https://github.com/maria-antoniak/poetry-eval/'\n",
        "    'raw/refs/heads/main/data/poetry-evaluation_public-domain-poems.csv'\n",
        ")\n",
        "\n",
        "# Keep sonnets & ghazals\n",
        "poems_df = poems_df[poems_df['form'].isin(['sonnet', 'ghazal'])]\n",
        "\n",
        "# Random 25 sonnets + 2 ghazals\n",
        "sample_df = poems_df[poems_df['form'] == 'sonnet'].sample(25)\n",
        "sample_df = pd.concat([sample_df, poems_df[poems_df['form'] == 'ghazal']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBlucCeTuDbz",
        "outputId": "5cd61e75-6800-4ccc-abbe-4d5874250710"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SqTw3A99hPDbTUxZ-OoJD4wGdl0ZF3Oz\n",
            "To: /content/brown_poems.csv\n",
            "100%|██████████| 3.18k/3.18k [00:00<00:00, 4.64MB/s]\n"
          ]
        }
      ],
      "source": [
        "# load brown poems\n",
        "import gdown\n",
        "url = \"https://drive.google.com/file/d/1SqTw3A99hPDbTUxZ-OoJD4wGdl0ZF3Oz/view?usp=sharing\"\n",
        "output = \"brown_poems.csv\"\n",
        "gdown.download(url=url, output=output, fuzzy=True)\n",
        "\n",
        "brown_df = pd.read_csv(\"brown_poems.csv\")\n",
        "\n",
        "# reduce sample_df columns\n",
        "sample_df = sample_df[['author', 'poem_title', 'poem_text', 'form']]\n",
        "\n",
        "# combine datasets\n",
        "combined_df = pd.concat([sample_df, brown_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0g0Z9s3uDjm"
      },
      "outputs": [],
      "source": [
        "prompt_template_start = '''\n",
        "Read the following poem and classify its form as: [sonnet, ghazal, duplex].\n",
        "You must choose exactly ONE.\n",
        "\n",
        "Return the answer in this format:\n",
        "\n",
        "1. Poetic Form: ...\n",
        "2. Elaborated Rationale: ...\n",
        "3. One-Word Summary: ...\n",
        "4. Confidence Score: ...\n",
        "\n",
        "Poem Text:\n",
        "'''\n",
        "\n",
        "prompt_template_end = '''\n",
        "\n",
        "Pick ONE of these forms: [sonnet, ghazal, duplex].\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOQDRV62uDp4"
      },
      "outputs": [],
      "source": [
        "def extract_response_fields(response):\n",
        "    \"\"\"Parse the classification output.\"\"\"\n",
        "    lines = response.strip().split('\\n')\n",
        "\n",
        "    result = {\n",
        "        'poetic_form': None,\n",
        "        'rationale': None,\n",
        "        'summary': None,\n",
        "        'confidence': None\n",
        "    }\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('1. Poetic Form:'):\n",
        "            result['poetic_form'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('2. Elaborated Rationale:'):\n",
        "            result['rationale'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('3. One-Word Summary:'):\n",
        "            result['summary'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('4. Confidence Score:'):\n",
        "            result['confidence'] = line.split(':', 1)[1].strip()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_45MSQYbuuvd"
      },
      "outputs": [],
      "source": [
        "# Classify poems using Claude\n",
        "for index, row in combined_df.iterrows():\n",
        "    prompt = prompt_template_start + row['poem_text'] + prompt_template_end\n",
        "    response = query_claude(prompt)\n",
        "    fields = extract_response_fields(response)\n",
        "\n",
        "    combined_df.at[index, 'poetic_form'] = fields['poetic_form']\n",
        "    combined_df.at[index, 'rationale'] = fields['rationale']\n",
        "    combined_df.at[index, 'summary'] = fields['summary']\n",
        "    combined_df.at[index, 'confidence'] = fields['confidence']\n",
        "\n",
        "combined_df.to_csv(\"combined_df_claude.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGY-B1Bkuu5E"
      },
      "outputs": [],
      "source": [
        "# Subjects for poem generation\n",
        "subjects = [\n",
        "    \"abuse\", \"activities\", \"arts & sciences\", \"christianity\", \"chronic illness\",\n",
        "    \"crime & punishment\", \"cycles\", \"desire & passion\", \"doubt & contemplation\",\n",
        "    \"family & ancestors\", \"gender & sexuality\", \"greek & roman mythology\",\n",
        "    \"history & politics\", \"home life\", \"hope\", \"humor & satire\",\n",
        "    \"indoor activities\", \"life choices\", \"lgbtq+\", \"living\", \"love\",\n",
        "    \"love death avoidance\", \"memory & nostalgia\", \"men & women\",\n",
        "    \"mythology & folklore\", \"nature\", \"power\", \"poetry & poets\",\n",
        "    \"race & ethnicity\", \"relationships\", \"romantic love\", \"sexual violence\",\n",
        "    \"sorrow & grieving\", \"social commentaries\", \"subjugation\", \"the mind\",\n",
        "    \"trees and flowers\", \"truth\", \"twilight\", \"urban environment\",\n",
        "    \"war & conflict\", \"weather\", \"youth\"\n",
        "]\n",
        "\n",
        "BROWN_RULES = \"\"\"\n",
        "Write a poem in the Duplex form as defined by Jericho Brown.\n",
        "You MUST follow ALL of these rules:\n",
        "\n",
        "1. The poem has exactly 14 lines.\n",
        "2. Each line must contain between 9 and 11 syllables.\n",
        "3. The poem should blend qualities of ghazal, sonnet, and blues traditions.\n",
        "4. Line 1 is repeated as Line 14.\n",
        "5. Line 2 must reinterpret Line 1 in an unexpected way.\n",
        "6. Line 2 is repeated as Line 3.\n",
        "7. Line 4 must reinterpret Line 3 in an unexpected way.\n",
        "8. This pattern of echo / reinterpretation continues until Line 13.\n",
        "9. Line 13 becomes the first line of the couplet that leads to the final line (Line 14).\n",
        "10. The poem's theme should be rooted in emotional tension, reflection, or personal revelation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E2lypxuTuu7-",
        "outputId": "d01c6087-850c-45c9-92cd-3456fdf60c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simple Duplex poems generated and saved.\n"
          ]
        }
      ],
      "source": [
        "def generate_general_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}.\"\n",
        "\n",
        "def generate_figurative_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}. Do not use the words {subject} or {form}.\"\n",
        "\n",
        "def generate_specific_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}. Make it about something specific.\"\n",
        "\n",
        "# Generate simple Duplex poems\n",
        "new_poems_df = pd.DataFrame(columns=['subject', 'form', 'prompt_type', 'poem_text'])\n",
        "\n",
        "for subject in subjects:\n",
        "    genPrompt = generate_general_prompt(subject)\n",
        "    figPrompt = generate_figurative_prompt(subject)\n",
        "    specPrompt = generate_specific_prompt(subject)\n",
        "\n",
        "    genResponse = query_claude(genPrompt)\n",
        "    figResponse = query_claude(figPrompt)\n",
        "    specResponse = query_claude(specPrompt)\n",
        "\n",
        "    new_poems_df.loc[len(new_poems_df)] = [subject, \"Duplex\", \"general\", genResponse]\n",
        "    new_poems_df.loc[len(new_poems_df)] = [subject, \"Duplex\", \"figurative\", figResponse]\n",
        "    new_poems_df.loc[len(new_poems_df)] = [subject, \"Duplex\", \"specific\", specResponse]\n",
        "\n",
        "new_poems_df.to_csv(\"new_poems_df_claude.csv\", index=False)\n",
        "\n",
        "print(\"Simple Duplex poems generated and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "av_QQLNouu_j",
        "outputId": "4ecea2b7-7ed5-4c69-cf38-55bce5ec0a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Duplex poems with Brown rules generated and saved.\n"
          ]
        }
      ],
      "source": [
        "def generate_general_prompt_brown(subject, form=\"Duplex\"):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a poem about the subject of {subject} in the form: {form}.\\n\"\n",
        "        f\"The poem MUST follow all Duplex rules above.\"\n",
        "    )\n",
        "\n",
        "def generate_figurative_prompt_brown(subject, form=\"Duplex\"):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a poem about the subject of {subject} in the form: {form}.\\n\"\n",
        "        f\"Do NOT use the words '{subject}' or '{form}' anywhere in the poem.\\n\"\n",
        "        f\"The poem MUST follow all Duplex rules above.\"\n",
        "    )\n",
        "\n",
        "def generate_specific_prompt_brown(subject, form=\"Duplex\"):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a poem about the subject of {subject} in the form: {form}.\\n\"\n",
        "        f\"Make the poem about a very specific moment, object, place, or memory.\\n\"\n",
        "        f\"The poem MUST follow all Duplex rules above.\"\n",
        "    )\n",
        "\n",
        "# Generate Duplex poems with Brown rules\n",
        "new_brown_poems_df = pd.DataFrame(\n",
        "    columns=['subject', 'form', 'prompt_type', 'poem_text']\n",
        ")\n",
        "\n",
        "for subject in subjects:\n",
        "    # Build 3 prompt types\n",
        "    genPrompt = generate_general_prompt_brown(subject)\n",
        "    figPrompt = generate_figurative_prompt_brown(subject)\n",
        "    specPrompt = generate_specific_prompt_brown(subject)\n",
        "\n",
        "    # Call Claude\n",
        "    genResponse = query_claude(genPrompt)\n",
        "    figResponse = query_claude(figPrompt)\n",
        "    specResponse = query_claude(specPrompt)\n",
        "\n",
        "    # Store results\n",
        "    new_brown_poems_df.loc[len(new_brown_poems_df)] = [\n",
        "        subject, \"Duplex\", \"general\", genResponse\n",
        "    ]\n",
        "    new_brown_poems_df.loc[len(new_brown_poems_df)] = [\n",
        "        subject, \"Duplex\", \"figurative\", figResponse\n",
        "    ]\n",
        "    new_brown_poems_df.loc[len(new_brown_poems_df)] = [\n",
        "        subject, \"Duplex\", \"specific\", specResponse\n",
        "    ]\n",
        "\n",
        "new_brown_poems_df.to_csv(\"new_brown_poems_df_claude.csv\", index=False)\n",
        "\n",
        "print(\"All Duplex poems with Brown rules generated and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rAoExwPxxYmk",
        "outputId": "a878c0a4-a746-442d-9f68-a9f6346910aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== All tasks complete using Claude API ===\n",
            "Files created:\n",
            "  - combined_df_claude.csv\n",
            "  - new_poems_df_claude.csv\n",
            "  - new_brown_poems_df_claude.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== All tasks complete using Claude API ===\")\n",
        "print(f\"Files created:\")\n",
        "print(\"  - combined_df_claude.csv\")\n",
        "print(\"  - new_poems_df_claude.csv\")\n",
        "print(\"  - new_brown_poems_df_claude.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6dk0lUDd7Pc"
      },
      "source": [
        "Olmo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BH8Rnpjtd_zB",
        "outputId": "bde32524-aa41-445c-afbf-8ec64c36ecdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "HF_API_KEY = \"KEY_GOES_HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hsGCxlt6d__9"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "HF_TOKEN = \"TOKEN_GOES_HERE\"\n",
        "\n",
        "client_olmo = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=HF_TOKEN,\n",
        ")\n",
        "\n",
        "def query_olmo(prompt):\n",
        "    completion = client_olmo.chat.completions.create(\n",
        "        model=\"allenai/Olmo-3-7B-Instruct:publicai\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=800,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    return completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A4LkCuXKeADo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "poems_df = pd.read_csv(\n",
        "    'https://github.com/maria-antoniak/poetry-eval/raw/refs/heads/main/data/poetry-evaluation_public-domain-poems.csv'\n",
        ")\n",
        "poems_df = poems_df[poems_df['form'].isin(['sonnet', 'ghazal'])]\n",
        "\n",
        "sample_df = poems_df[poems_df['form'] == 'sonnet'].sample(25)\n",
        "sample_df = pd.concat([sample_df, poems_df[poems_df['form'] == 'ghazal']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AkPF-Y5MeAGE",
        "outputId": "2fe4a19a-9583-4759-ec85-fa28678bd328"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SqTw3A99hPDbTUxZ-OoJD4wGdl0ZF3Oz\n",
            "To: /content/brown_poems.csv\n",
            "100%|██████████| 3.18k/3.18k [00:00<00:00, 8.71MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load Brown poems\n",
        "import gdown\n",
        "url = \"https://drive.google.com/file/d/1SqTw3A99hPDbTUxZ-OoJD4wGdl0ZF3Oz/view?usp=sharing\"\n",
        "output = \"brown_poems.csv\"\n",
        "gdown.download(url=url, output=output, fuzzy=True)\n",
        "brown_df = pd.read_csv(\"brown_poems.csv\")\n",
        "\n",
        "sample_df = sample_df[['author', 'poem_title', 'poem_text', 'form']]\n",
        "combined_df_olmo = pd.concat([sample_df, brown_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x40Ca5l_hbn2"
      },
      "outputs": [],
      "source": [
        "# Classification template\n",
        "prompt_template_start = '''\n",
        "Read the following poem and classify its form as: [sonnet, ghazal, duplex].\n",
        "You must choose exactly ONE.\n",
        "\n",
        "Return the answer in this format:\n",
        "\n",
        "1. Poetic Form: ...\n",
        "2. Elaborated Rationale: ...\n",
        "3. One-Word Summary: ...\n",
        "4. Confidence Score: (0.0-1.0)\n",
        "\n",
        "Poem Text:\n",
        "'''\n",
        "\n",
        "prompt_template_end = '''\n",
        "\n",
        "Pick ONE of these forms: [sonnet, ghazal, duplex].\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kwdpMsbNhbwE"
      },
      "outputs": [],
      "source": [
        "# Classification function\n",
        "def extract_response_fields(response):\n",
        "    \"\"\"Parse Olmo's classification output\"\"\"\n",
        "    lines = response.strip().split('\\n')\n",
        "    result = {\n",
        "        'poetic_form': None,\n",
        "        'rationale': None,\n",
        "        'summary': None,\n",
        "        'confidence': None\n",
        "    }\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('1. Poetic Form:'):\n",
        "            result['poetic_form'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('2. Elaborated Rationale:'):\n",
        "            result['rationale'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('3. One-Word Summary:'):\n",
        "            result['summary'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('4. Confidence Score:'):\n",
        "            try:\n",
        "                result['confidence'] = float(line.split(':', 1)[1].strip())\n",
        "            except:\n",
        "                result['confidence'] = 0.0\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cowcb_tNhb2P",
        "outputId": "03387e7e-f251-4bd8-a702-0eae83b0b0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification complete. Results saved to combined_df_olmo.csv\n"
          ]
        }
      ],
      "source": [
        "# Process poems\n",
        "for index, row in combined_df_olmo.iterrows():\n",
        "    prompt = prompt_template_start + row['poem_text'] + prompt_template_end\n",
        "    response = query_olmo(prompt)\n",
        "    fields = extract_response_fields(response)\n",
        "\n",
        "    combined_df_olmo.at[index, 'poetic_form'] = fields['poetic_form']\n",
        "    combined_df_olmo.at[index, 'rationale'] = fields['rationale']\n",
        "    combined_df_olmo.at[index, 'summary'] = fields['summary']\n",
        "    combined_df_olmo.at[index, 'confidence'] = fields['confidence']\n",
        "\n",
        "combined_df_olmo.to_csv(\"combined_df_olmo.csv\", index=False)\n",
        "print(f\"Classification complete. Results saved to combined_df_olmo.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XZdJFHVxnkXr",
        "outputId": "6a66b5e2-46b1-4477-b69d-98e21e5f97b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Olmo Poem Generation ---\n"
          ]
        }
      ],
      "source": [
        "# --- Poem Generation with Olmo ---\n",
        "print(\"\\n--- Starting Olmo Poem Generation ---\")\n",
        "\n",
        "subjects = [\n",
        "    \"abuse\", \"activities\", \"arts & sciences\", \"christianity\", \"chronic illness\",\n",
        "    \"crime & punishment\", \"cycles\", \"desire & passion\", \"doubt & contemplation\",\n",
        "    \"family & ancestors\", \"gender & sexuality\", \"greek & roman mythology\",\n",
        "    \"history & politics\", \"home life\", \"hope\", \"humor & satire\",\n",
        "    \"indoor activities\", \"life choices\", \"lgbtq+\", \"living\", \"love\",\n",
        "    \"love death avoidance\", \"memory & nostalgia\", \"men & women\",\n",
        "    \"mythology & folklore\", \"nature\", \"power\", \"poetry & poets\",\n",
        "    \"race & ethnicity\", \"relationships\", \"romantic love\", \"sexual violence\",\n",
        "    \"sorrow & grieving\", \"social commentaries\", \"subjugation\", \"the mind\",\n",
        "    \"trees and flowers\", \"truth\", \"twilight\", \"urban environment\",\n",
        "    \"war & conflict\", \"weather\", \"youth\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jyNcX_Sunkax",
        "outputId": "09369db5-f2e0-4cce-c6bf-945352d189ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved olmo_general_poems.csv\n"
          ]
        }
      ],
      "source": [
        "# Standard prompts\n",
        "def generate_general_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about the subject of {subject} in the form: {form}.\"\n",
        "\n",
        "def generate_figurative_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a poem about {subject} using {form} techniques. Avoid using the words '{subject}' or '{form}'.\"\n",
        "\n",
        "def generate_specific_prompt(subject, form=\"Duplex\"):\n",
        "    return f\"Write a specific, concrete poem about {subject} following {form} conventions.\"\n",
        "\n",
        "\n",
        "new_poems_df = pd.DataFrame(columns=['subject', 'form', 'prompt_type', 'poem_text'])\n",
        "\n",
        "\n",
        "for subject in subjects:\n",
        "\n",
        "    genPrompt = generate_general_prompt(subject)\n",
        "    figPrompt = generate_figurative_prompt(subject)\n",
        "    specPrompt = generate_specific_prompt(subject)\n",
        "\n",
        "    genResponse = query_olmo(genPrompt)\n",
        "    figResponse = query_olmo(figPrompt)\n",
        "    specResponse = query_olmo(specPrompt)\n",
        "\n",
        "    # Use concat (append is deprecated)\n",
        "    rows = [\n",
        "        {'subject': subject, 'form': 'Duplex', 'prompt_type': 'general',   'poem_text': genResponse},\n",
        "        {'subject': subject, 'form': 'Duplex', 'prompt_type': 'figurative','poem_text': figResponse},\n",
        "        {'subject': subject, 'form': 'Duplex', 'prompt_type': 'specific',  'poem_text': specResponse},\n",
        "    ]\n",
        "\n",
        "    new_poems_df = pd.concat([new_poems_df, pd.DataFrame(rows)], ignore_index=True)\n",
        "\n",
        "\n",
        "new_poems_df.to_csv(\"olmo_general_poems.csv\", index=False)\n",
        "print(\"Saved olmo_general_poems.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N6YH_R9unkd2"
      },
      "outputs": [],
      "source": [
        "# Brown rules prompts\n",
        "BROWN_RULES = \"\"\"\n",
        "Follow these strict Duplex rules:\n",
        "1. Exactly 14 lines\n",
        "2. 9-11 syllables per line\n",
        "3. Blend sonnet, ghazal, and blues elements\n",
        "4. Line 1 = Line 14\n",
        "5. Line 2 reinterprets Line 1 unexpectedly\n",
        "6. Line 2 = Line 3\n",
        "7. Line 4 reinterprets Line 3 unexpectedly\n",
        "8. Continue echo/reinterpret pattern through Line 13\n",
        "9. Line 13 starts the final couplet\n",
        "10. Theme: emotional tension/reflection\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9AUv_-xgnkks"
      },
      "outputs": [],
      "source": [
        "brown_df   = pd.DataFrame(columns=['subject', 'form', 'prompt_type', 'poem_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4JUNTF0Vnkid",
        "outputId": "d7b5ed6f-7d35-4332-fd68-e74d47a8bd47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Poem generation complete. Files saved:\n",
            "  - olmo_general_poems.csv\n",
            "  - olmo_brown_poems.csv\n"
          ]
        }
      ],
      "source": [
        "def generate_brown_general_prompt(subject):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a Duplex poem about the subject '{subject}'. \"\n",
        "        f\"Follow ALL Duplex rules exactly.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_brown_figurative_prompt(subject):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a Duplex poem about the subject '{subject}'. \"\n",
        "        f\"Follow ALL Duplex rules exactly. \"\n",
        "        f\"Do NOT use the words '{subject}' or 'Duplex'.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_brown_specific_prompt(subject):\n",
        "    return (\n",
        "        f\"{BROWN_RULES}\\n\\n\"\n",
        "        f\"Write a very specific Duplex poem about a concrete moment, object, or memory \"\n",
        "        f\"related to '{subject}'. Follow ALL Duplex rules exactly.\"\n",
        "    )\n",
        "\n",
        "\n",
        "brown_poems_df = pd.DataFrame(columns=['subject', 'form', 'prompt_type', 'poem_text'])\n",
        "\n",
        "\n",
        "# ---- GENERATE POEMS ----\n",
        "for subject in subjects:\n",
        "\n",
        "    genPrompt = generate_brown_general_prompt(subject)\n",
        "    figPrompt = generate_brown_figurative_prompt(subject)\n",
        "    specPrompt = generate_brown_specific_prompt(subject)\n",
        "\n",
        "    genResponse = query_olmo(genPrompt)\n",
        "    figResponse = query_olmo(figPrompt)\n",
        "    specResponse = query_olmo(specPrompt)\n",
        "\n",
        "    # collect rows\n",
        "    rows = [\n",
        "        {'subject': subject, 'form': 'Duplex', 'prompt_type': 'general',   'poem_text': genResponse},\n",
        "        {'subject': subject, 'form': 'Duplex', 'prompt_type': 'figurative','poem_text': figResponse},\n",
        "        {'subject': subject, 'form': 'Duplex', 'prompt_type': 'specific',  'poem_text': specResponse},\n",
        "    ]\n",
        "\n",
        "\n",
        "    brown_poems_df = pd.concat([brown_poems_df, pd.DataFrame(rows)], ignore_index=True)\n",
        "\n",
        "\n",
        "# ---- SAVE FILE ----\n",
        "brown_poems_df.to_csv(\"olmo_brown_poems.csv\", index=False)\n",
        "\n",
        "print(\"\\nPoem generation complete. Files saved:\")\n",
        "print(\"  - olmo_general_poems.csv\")\n",
        "print(\"  - olmo_brown_poems.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
